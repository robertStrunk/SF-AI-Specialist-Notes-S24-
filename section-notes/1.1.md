# Salesforce Certified AI Specialist (Summer 24)

### Exam Topic
Identify the security, privacy, and grounding features of the Einstein Trust Layer

### Key Concepts
1. **Data Access Governance**: The Einstein trust layer is the "Watchdog" of the data. Any models or aps that reach for the data have to go through the trust layer. 
2. **Dynamic Grounding**: The injection/binding of customer data into a prompt before it is sent to the LLM.
3. **Data Masking**: The obfuscation of sensitive data after it is grounded to the prompt before it is sent to the LLM.
4. **Zero Data Retention**: After the LLM has processed a prompt, and data referenced won't be stored by the LLM provider.
5. **Toxicity Detection**: After a response is returned from an LLM, the Salesforce Trust Layer assigns a toxicity score to the response. 

### Key Mechanisms
1. **Einstein Trust Layer**
2. **Einstein Feedback**

### Details

The Einstein Trust Layer is a security and governance framework in Salesforce that ensures the responsible, ethical, and transparent use of artificial intelligence (AI) in the platform's products, especially those powered by Salesforce Einstein (Salesforceâ€™s AI technology). It acts as a safeguard to build trust in the AI-powered features by protecting data privacy, enforcing ethical AI practices, and ensuring compliance with industry standards.

![Where the Einstein Trust Layer fits into the application stack.](../files/Layers.png)


Any gen ai requests or responses have to pass through this layer. 



### Resources
- [LINK TODO](URL)

**Next Section**: [Next](./1.2.md)<br />
**Main**: [Main](../README.md)